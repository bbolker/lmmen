\documentclass{article}

\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{graphicx,psfrag,wasysym,multirow}
\usepackage[pdftex,bookmarks=true]{hyperref}
\usepackage{caption,subcaption}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{authblk,hyperref,xcolor}
\usepackage[english]{babel}
\usepackage{natbib}
\bibliographystyle{abbrvnat}
\setcitestyle{authoryear,open={(},close={)}}

\newtheorem{thm}{Theorem}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\author[1]{Jonathan Sidi}
\author[1]{Ya'acov Ritov} 
\author[2]{Lyle Ungar} 

\affil[1]{Department of Statistics, Hebrew University in Jerusalem}
\affil[2]{Computer and Information Statistics, University of Pennsylvania}

\renewcommand\Authands{ and }
\title{Regularization and Classification of Linear Mixed Models via the Elastic Net Penalty \\ with Application to the Good Judgment Project\footnote{This research was supported by a research contract to the University of Pennsylvania and the University of California from the Intelligence Advanced Research Projects Activity (IARPA) via the Department of Interior National Business Center contract number D11PC20061. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright annotation thereon. Disclaimer: The views and conclusions expressed herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoI/NBC, or the U.S. Government.}}

\begin{document}
\SweaveOpts{concordance=TRUE}

<<echo=FALSE>>=
library(ggplot2);library(scales);library(dplyr);library(grid)
load('../sim.output/graph_data2.rdata')
load('../sim.output/glmmlassoScen1.Rdata')
load('../sim.output/glmmlassoScen2.Rdata')

load('../sim.output/lmmlassoScen1.Rdata')
load('../sim.output/lmmlassoScen2.Rdata')
load('../sim.output/lmmlassoScen3.Rdata')

load('../sim.output/scadScen1.Rdata')
load('../sim.output/scadScen2.Rdata')
load('../sim.output/scadScen3.Rdata')

colnames(sim.lmmlasso3)[1:20]<-c('(Intercept)',paste0('X',1:9),paste0('V',1:10))
load('../sim.output/lmmlassoScen4.Rdata')
colnames(sim.lmmlasso4)[1:14]<-c('(Intercept)',paste0('X',1:9),paste0('V',1:4))

colnames(sim.scad1)<-gsub('^z','V',colnames(sim.scad1))
colnames(sim.scad2)<-gsub('^z','V',colnames(sim.scad2))
colnames(sim.scad3)<-gsub('^z','V',colnames(sim.scad3))

sim.lmmlasso<-list(sim.lmmlasso1,sim.lmmlasso2,sim.lmmlasso3,sim.lmmlasso4)
sim.glmmlasso<-list(glmmlasso.scen1,glmmlasso.scen2)
sim.scad<-list(sim.scad1,sim.scad2,sim.scad3)

names(sim.lmmlasso)<-c(1:4)
names(sim.glmmlasso)<-c(1:2)
names(sim.scad)<-c(1:3)

sim.lmmlasso<-plyr::ldply(sim.lmmlasso,.fun=function(data){
  x<-data%>%data.frame()%>%
    mutate(iterid=1:nrow(.),iter=lambda.opt/5)%>%select(-lambda.opt)%>%
    reshape2::melt(.,c('iterid','iter'),value.name='est')%>%filter(grepl('[0-9]|bic',variable))
  
  x$type<-as.character(x$variable)
  x$type[grepl('^X',x$type)]<-'FIXED'
  x$type[grepl('^V',x$type)]<-'STDDEV'
  x$type[grepl('^bic',x$type)]<-'BIC'
  
  x=x%>%group_by(iterid,type)%>%mutate(id=1:n())
  x$simtype='lmmlasso'
  
  x<-x[,head(names(fit.min.all),-1)]  
},.id='ex')%>%mutate(ex=as.numeric(as.character(ex)))

sim.scad<-plyr::ldply(sim.scad,.fun=function(data){
  x<-data%>%data.frame()%>%
    mutate(iterid=1:nrow(.),iter=1)%>%
    reshape2::melt(.,c('iterid','iter'),value.name='est')%>%
    filter(grepl('[1-9]|bic',variable))
  
  x$type<-as.character(x$variable)
  x$type[grepl('^X',x$type)]<-'FIXED'
  x$type[grepl('^V',x$type)]<-'STDDEV'
  x$type[grepl('^bic',x$type)]<-'BIC'
  
  x=x%>%group_by(iterid,type)%>%mutate(id=1:n())
  x$simtype='scad'
  
  x<-x[,head(names(fit.min.all),-1)]  
},.id='ex')%>%mutate(ex=as.numeric(as.character(ex)))

sim.glmmlasso<-plyr::ldply(sim.glmmlasso,.fun=function(data){
  x<-data%>%data.frame()%>%
    mutate(iterid=1:nrow(.),iter=lambda.opt/5)%>%select(-lambda.opt)%>%
    reshape2::melt(.,c('iterid','iter'),value.name='est')%>%filter(grepl('[0-9]|subject|bic',variable))
  
  x$type<-as.character(x$variable)
  x$type[grepl('^X',x$type)]<-'FIXED'
  x$type[grepl('^subject',x$type)]<-'STDDEV'
  x$type[grepl('^bic',x$type)]<-'BIC'
  
  x$est[x$type=='STDDEV']=sqrt(x$est[x$type=='STDDEV'])
  
  x=x%>%group_by(iterid,type)%>%mutate(id=1:n())
  x$simtype='glmmlasso'
  
  x<-x[,head(names(fit.min.all),-1)]  
},.id='ex')%>%mutate(ex=as.numeric(as.character(ex)))

fit.min.all<-rbind(fit.min.all,sim.lmmlasso,sim.glmmlasso,sim.scad)


vplayout <- function(x, y) viewport(layout.pos.row = x, layout.pos.col = y)

fs=21

# real_param=data.frame(ex=c(rep(seq(1,5),c(rep(9,4),200)),rep(seq(1,5),c(4,4,10,4,4))),
#                       id=c(rep(seq(1,9),4),seq(1,200),rep(seq(1,4),2),seq(1,10),rep(seq(1,4),2)),
#                       type=rep(c("FIXED","STDDEV"),rep(c(236,26))),
#                       p=c(rep(c(1,1,rep(0,7)),2),1,0,1,rep(0,6),rep(1,3),rep(0,6),rep(1,20),rep(0,180),
#                           rep(c(rep(1,3),0),2),rep(1,3),rep(0,7),rep(c(rep(1,3),0),2)))

temp=left_join(fit.min.all%>%filter(type!="BIC")%>%mutate(type=factor(type)),real_param, by=c("ex","type","id"))%>% mutate(nz=as.numeric(as.numeric(est!=0)==p))%>%group_by(ex,simtype,type,iterid)%>%
  summarise(truez=sum(nz))

temp=left_join(temp,real_param%>%group_by(ex,type)%>%
                 summarise(n=n()),by=c("ex","type"))%>%
                mutate(truez=ifelse((truez/n)>1,truez/2,truez),pct=truez/n)

temp1=temp%>%group_by(simtype,ex,iterid)%>%
  summarise(truez=sum(truez),n=sum(n))%>%mutate(pct=truez/n)

a1<-rbind(
  temp1%>%group_by(simtype,ex)%>%summarise(pct=mean(pct))%>%mutate(type="MODEL"),
  temp%>%group_by(simtype,type,ex)%>%summarise(pct=mean(pct)))%>%
  mutate(pct.type="Mean Percent")

a2<-rbind(temp1%>%mutate(type="MODEL",all=as.numeric(pct==1))%>%group_by(type,simtype,ex,all)%>%summarise(pct=1-(n()/200))%>%filter(all==0)%>%select(-all),temp%>%mutate(all=as.numeric(pct==1))%>%group_by(type,simtype,ex,all)%>%summarise(pct=1-(n()/200))%>%filter(all==0)%>%select(-all))%>%
    ungroup%>%mutate(pct.type="Oracle")

a3<-expand.grid(type=c("MODEL","FIXED","STDDEV"),pct.type=c("Mean Percent","Oracle"))%>%mutate(simtype="penlme",ex=5,pct=0)

temp.compare=bind_rows(a1,a2,a3)%>%ungroup%>%
  arrange(simtype,type,pct.type,ex)

temp.compare$type=factor(temp.compare$type,levels=unique(temp.compare$type),
                         labels=c("Model","Fixed Effects","Random Effects"))

temp.compare$simtype=factor(temp.compare$simtype,
                            labels=c('GLMMLASSO',"LMMEN",'LMMLASSO',"Pen.LME","SCAD"))

p.compare= temp.compare%>%filter(!is.na(pct))%>%mutate(ex=factor(ex))%>%
  ggplot(aes(x=ex,y=pct,fill=simtype))+geom_bar(stat="identity",position="dodge")+facet_grid(pct.type~type)+theme_bw(base_size = fs)+
  ylab("Percent")+xlab("Scenario")+
  scale_fill_discrete(name="Simulation Type")+theme(legend.position="bottom")+
  scale_y_continuous(labels = percent)+theme(legend.position="bottom")

# fit.min.ex5=fit.min.all%>%filter(type!="BIC",ex==5)%>%mutate(id=ifelse(id>20,21,id))
# fit.min.ex5$id=factor(fit.min.ex5$id,labels=c(seq(1,20),"+20"))
# 
# ggplot(fit.min.ex5%>%filter(type=="FIXED"),aes(x=factor(id),y=est,fill=simtype))+ geom_boxplot()+facet_wrap(ex~type,scales="free",ncol=1)+theme(axis.ticks=element_blank(),axis.text.x=element_blank())

# case.full=data.frame(simtype=rep(c("glmnet","lme4","lmmen"),rep(49,3)),id=rep(c(1:40,1:9),3),type=rep(rep(c("fixed","stddev"),c(40,9)),3))

temp.case=case.fit.min.all%>%filter(type!="BIC")%>%mutate(nz=ifelse(est!=0,1,0))%>%group_by(simtype,type,id,nz)%>%summarise(pct=n()/100,mest=mean(est))%>%filter(nz==1)%>%select(-nz)

temp.case$simtype=factor(temp.case$simtype,levels=c("lme4","glmnet","lmmen"),labels=c("lme4","GLMNET","LMMEN"))
temp.case$type=toupper(temp.case$type)

p.case=ggplot(temp.case%>%filter(id!=36),aes(x=factor(id),y=mest,fill=pct))+geom_bar(stat="identity",position="dodge")+facet_grid(simtype~type,scales="free_x")+theme_bw()+scale_fill_discrete(name="Persistency",breaks=seq(0,1,0.1),labels=percent)+scale_x_discrete(labels=seq(1:39))+ylab("Mean Parameter Estimate")+xlab("Parameter")

gen.plot=fit.min.all%>%
  dplyr::mutate(id=ifelse(id>20,21,id))%>%
  dplyr::filter(type!="BIC")

gen.plot$type=factor(gen.plot$type,labels=c("Fixed Effects","Random Effects"))

gen.plot$simtype.lbl=factor(gen.plot$simtype,labels=c('GLMMLASSO',"LMMEN",'LMMLASSO',"Pen.LME","SCAD"))

gen.plot=gen.plot%>%mutate(id=factor(id,labels=c(1:20,"21+")),flabel=sprintf('%s: %s',ex,type))

gen.plot$simtype.lbl<-factor(gen.plot$simtype.lbl,levels=levels(gen.plot$simtype.lbl)[c(2,4,1,3,5)])

p4=gen.plot%>%plyr::dlply(c('ex'),.fun=function(df){
  yint<-df%>%mutate(type=as.character(type))%>%
    dplyr::distinct(flabel,type)%>%
    dplyr::left_join(data.frame(yint=c(0,1,3,2,1,0),type=c(rep('Fixed Effects',2),rep('Random Effects',4)),stringsAsFactors = FALSE),by='type')
  
  df%>%ggplot(aes(x=id,y=est,fill=simtype.lbl))+
    geom_boxplot()+
    facet_wrap(~flabel,scales="free",ncol=2)+
    xlab("Parameter")+
    ylab("Estimate")+
    scale_fill_discrete(name="Simulation Type")+
    theme_bw(base_size = fs)+
    theme(legend.position="bottom")+
    geom_hline(aes(yintercept=yint),linetype=2,data=yint)
})

p_scat=ggplot(case.panel$obs, aes(lmmen,glmnet))+ geom_point()+theme_bw(base_size = fs)+
  #geom_text(vjust=1,size=3)+
  geom_abline(intercept=0,slope=1,linetype="dashed")+xlim(min(case.panel$obs[,1:2]),max(case.panel$obs[,-1]))+ylim(min(case.panel$obs[,1:2]),max(case.panel$obs[,-1]))+ylab("GLMNET")+xlab("LMMEN")

case.panel$mae$type=factor(case.panel$mae$type,labels=c("LMMEN","GLMNET"))

p_mae=ggplot(case.panel$mae,aes(x=type,y=err,fill=type))+
  geom_boxplot()+
  xlab('Selection Type')+ylab('Mean Absolute Error')+theme_bw(base_size = fs)+
  scale_fill_discrete(guide=FALSE)

case.panel$fixed$Type=factor(case.panel$fixed$Type,labels=c("LMMEN","GLMNET"))

p_eps_f=ggplot(case.panel$fixed,aes(x=var,y=stat,fill=Type))+theme_bw(base_size = fs)+
  geom_bar(stat = "identity")+ theme(axis.text.x = element_blank(),axis.ticks=element_blank())+
  facet_wrap(~Type,nrow=2,scales="free_y")+ylab('% Persistence')+xlab('Fixed Effect')+
  scale_fill_discrete(guide=FALSE)+
  scale_y_continuous(labels = percent)

case.panel$ran$Type=factor(case.panel$ran$Type,labels=c("LMMEN"))

p_eps_r=ggplot(case.panel$ran,aes(x=factor(var),y=stat,fill=Type))+geom_bar(stat = "identity")+ylab('% Persistence')+xlab('Random Effect')+theme_bw(base_size = fs)+
  facet_wrap(~Type)+scale_y_continuous(limits=c(0,1),labels=percent)+  scale_fill_discrete(guide=FALSE)

@


\clearpage
\maketitle
\thispagestyle{empty}

% \vspace{2cm}
% \begin{center}
% Prospective Journals for Publication
% \begin{itemize}
% \item Journal of Statistical Planning
% \item Multivariate Analysis
% \item Computational Statistics and Data Analysis
% \item Statistical Analysis and Data Mining
% \item International Journal of Data Analysis Techniques and Strategies
% \end{itemize}
% \end{center}



\newpage
\begin{abstract}
Advances in the field of model selection and prediction via regularization has forged the ability of a variety of disciplines to classify and model large-scale data. Widely used methods which apply penalties in classification are the Least Absolute Shrinkage and Selection Operator (LASSO), the Adaptive LASSO and the Elastic Net. These methods have predominately been used to classify problems of Generalized Linear Models (GLM) in which the dependency of the covariance structure is assumed to be independent. This assumption is not commonly met in practical data and the ability to model such dependencies is integral in fitting the data correctly, such data is modeled using Linear Mixed Models (LMM). Recent research applying LASSO and Adaptive LASSO to LMM's has produced promising initial results of identifying both the random and fixed effects found in data, proving both consistency and an oracle optimality. However, an inherent drawback to those variable selection methods is their performance under high correlation between covariates. To overcome this we introduce the Elastic Net penalty to LMM selection. This penalty has been found to reduce the prediction error in data with high correlation between variables; such a characteristic can be utilized in more complex data designs while optimizing the LMM problem. Findings are tested through simulations and a case study using data accumulated in an longitudinal study where probabilistic forecasts are derived from crowd sentiment. The data structure consists repeated measures and a large number of fixed and random covariates.
\end{abstract}
\newpage
	\section{Introduction}
		Generalized Linear Mixed models (GLMM) \cite{BreslowClayton1993} have been applied in a variety of fields to study data designs with between-subject variation. Such designs include longitudinal, repeated measures and clustered data and have been studied thoroughly in the low dimension setting, e.g. \cite{Bates2010} and \cite{searle1992variance}. In these settings the linear predictor contains in addition to fixed effects, found in Generalized Linear Models (GLM), latent random effects which capture the unique design pertaining to the data. These random effects usually are assumed to have a centered parametric distribution belonging to the exponential family.
		
  Advances in the field of model selection and prediction via regularization, using different penalty terms, has forged the ability of a variety of disciplines to classify and model large-scale data. Widely used methods which apply penalties in classification are the Least Absolute Shrinkage and Selection Operator (LASSO), the Adaptive LASSO and the Elastic Net. These methods have predominately been used to classify problems of GLM, \cite{FHT2010} and \cite{VandeGeer2008}, in which the dependency of the covariance structure is assumed to be independent. This assumption in practical data is not commonly met and the ability to model such dependencies is integral in fitting the data correctly, such data is modeled using LMM and GLMMs.

  Recent research \cite{SchelldorferBuhlmann2011} and \cite{BKG2010} apply the LASSO and Adaptive LASSO respectively to LMMs and have produced promising initial results of identifying both the random and fixed effects found in data, proving both consistency and an oracle optimality. These two articles apply a penalty to the LMM optimization, while achieving this in two distinct approaches. This paper, proposes a new algorithm, LMMEN that attempts to utilize the advantages of each method and submit a new type of penalty which better captures the design of the LMM. Comparisons to each method will be done through simulations and a case study.
		
\begin{subsection}{Model}
    The GLMM is defined as having $m$ subjects in the sample. For the $i$th subject the response variable is denoted as $y_{ij}$ for the $j$th observation. The training data \textbf{X} can be defined as two groups of covariates: the fixed effects covariates vector denoted as $x_{ij}$ with dimensions $p\times 1$ and the random effects covariates vector denoted as $z_{ij}$ with dimensions $q\times 1$.
    
    $y_{ij}$ are assumed to be conditionally independent given the subject-specific random effects, $b_i$, with a conditional mean $E[y_{ij}|b_i]=\mu_{ij}$ and a conditional variance $var(y_{ij}|b_i)=\phi\omega^{-1}_{ij}\nu(\mu_{ij})$. Where $\phi$ is a positive dispersion parameter, $\omega_{ij}$ is a pre-specified weight, and $\nu(\cdot)$ is the variance function. The relationship between $\mu_{ij}$ to \textbf{X} is defined as 
%		
		\begin{equation}
		g(\mu_{ij})=x^t_{ij}\beta+z^t_{ij}b_i
		\end{equation}
%		
		where $g(\cdot)$ is a strictly increasing link function, $\beta$ is the fixed effects coefficient vector for $x$ and $b_i$ is the subject-specific random effects for $z$. $y_{ij}$ are assumed to be independent and of the form $y_{ij}|b_i\sim F_y$ and $b_i$ is assumed to be of the form $b_i\sim F_b$. Specification of $F_y$ and $F_b$ are predominately assumed to be normal, i.e.:
%
		\begin{eqnarray}
				F_y&\sim& N(\mu_{ij},\phi\omega^{-1}_{ij}\nu(\mu_{ij}))\\
				F_b&\sim& N(0,D(\psi)) 
		\end{eqnarray}
%
where $\psi$ is a $c \times 1$ vector of variance components in the covariance matrix of the random effects $D$. Under the identity link function with normal distribution we define the LMM
%
		\begin{equation}
		\label{eq:LMM}
		\begin{split}
		y_i&=x^t_{ij}\beta+z^t_{ij}b_i+\epsilon_i,\\
		\epsilon_i&\sim N(0,\sigma^2I_{n_i})
		\end{split}
		\end{equation}
%		
\cite{McCullochNeuhaus2011} state that distribution specification may be affected by basic characteristics of the random effects distribution, such as dependence on a covariate or the cluster sample size.
For example, the mean or variance of $F_b$ depends on a covariate. When the mean of the random effects distribution depends on a covariate, a fundamental relationship is introduced between the covariate and the distribution, potentially creating a serious bias in estimating the form of the relationship between the covariate and the outcome. \cite{heagerty2001misspecified} show that the impact of highly unequal variances can lead to substantial bias.Such bias from distribution specification can cause unintended inference when testing between and within cluster covariates.
\end{subsection}

\cite{SchelldorferBuhlmann2011} defined the GLMMLASSO, which solves the log likelihood of the LMM problem via integral approximation (Laplace approximation) and submit the approximated function to numerical optimization. The advantage of integral approximation methods is to provide an actual objective function for optimization, which enables one to perform likelihood ratio tests among nested models and to compute likelihood-based fit statistics. The disadvantage of these methods is the difficulty of accommodating crossed random effects and multiple subject effects, and the inability to accommodate residual effect covariance structures, or even only residual effect over-dispersion. Moreover, the number of random effects should be small for integral approximation methods to be practically feasible. This disadvantage could potentially inhibit the estimation of random effects in a high dimensional data setting. The penalty term which is used on the approximated likelihood function is the $L_1$ penalty. The algorithm proposed penalizes only the fixed effects in the model, thereby estimating the parameters $\lbrace\beta,\theta,\phi\rbrace$ and predicting the random effects vector b using those estimates. The size of the tuning parameter is calculated  in two steps: first via the AIC criterion to generate a relevant set of variables and secondly via the BIC criterion to select the final set of active fixed effects which is an unbiased estimator of degrees of freedom in linear models.

\cite{BKG2010} apply linearization (Taylor expansion) to solve the LMM which is more aptly suited in models with correlated errors, a large number of random effects, crossed random effects, and multiple types of subjects. The disadvantages of this approach include the absence of a true objective function for the overall optimization process and potentially biased estimates.

The likelihood function is reparameterized via a modified Cholesky decomposition of the random effects covariance structure \cite{ChenDunson2003}. This augmentation allows for penalties on both the fixed and random effects. The penalty used in the optimization is the Adaptive Lasso, \cite{Zou2006}, which allows for large amount of shrinkage applied to the zero-coefficients while smaller amounts are used for the non-zero ones which then results in an estimator with improved efficiency and selection properties. The level of the tuning parameter is calculated using the BIC criterion.

\section{Reparameterization of the Generalized Linear Mixed Model}
This paper will utilize the reparameterization of the LMM model initially defined in \cite{ChenDunson2003}, and used in \cite{BKG2010}. This reparameterization offers a simple design which regularization penalties can be easily applied to the fixed and random effects simultaneously. The covariance matrix of the random effects $D$ is factorized as follows:
%
		\begin{equation}
			\label{eq:fact}
			D=\Lambda\Gamma\Gamma^t\Lambda
		\end{equation}
%		
Where $\Lambda=diag(\lambda_1,...,\lambda_q)$ is a $q\times q$ non-negative diagonal matrix with elements proportional to standard deviations  of the random effects, and $\Gamma$ is a lower triangular matrix that relates to the correlations among the random effects with the $(l,m)$ elements denoted $\gamma_{lm}$. The elements of $\Lambda$ are defined as having a positive probability of equaling zero, thus enabling a subset of random effects to be selected. $\Lambda$ and $\Gamma$ are identifiable due to the assumption that:
%
$$\lambda_l\ge 0,\gamma_{ll}=1 \text{ and }\gamma_{lm}=0 \text{, for } l=1,...,q;m=l+1,...,q$$
%		
Applying the modified decomposition \eqref{eq:fact} to the LMM model \eqref{eq:LMM} the reparameterized LMM is defined, where the covariance matrix of \textbf{$b_i$} is a function of $\Lambda,\Gamma$:
%		
		\begin{equation}
			y_i=x^t_{ij}\beta+z^t_{ij}\Lambda\Gamma b_i+\epsilon_i
		\end{equation}
%
	\section{Simultaneous Variable Selection and Estimation via Regularization Penalties}	
The Adaptive LASSO has been used as the penalty function on the modified LMM by \cite{BKG2010} due to its oracle qualities. Although, there are drawbacks to its use, the primary disadvantage is that candidate covariates correlated to variables chosen in the active set are dropped from the final solution. This characteristic has been found to be a drawback in large scale data with grouped covariates. Moreover, when solving the likelihood of the LMM we can see that the fixed and random effect are dependent.
%		
		\begin{equation}
		\label{eq:Loglik}
		L(\phi|y,b)=-\frac{N+mq}{2}\log(\sigma^2)-\frac{1}{2\sigma^2}(||y-Z(I_m\otimes D)(I_m\otimes \Gamma) b-X\beta||^2+b^tb),
		\end{equation}
		with $\otimes$ denoting the Kronker product.
%

To overcome these issues we apply a variation on the Elastic Net penalty to the reparameterized likelihood function, \eqref{eq:Loglik}. The standard Elastic Net penalty, \cite{FHT2010}, is designed to be applied on a fixed effects model where only $\beta$ is penalized, as seen in \eqref{eq:EN}. In this formulation the problem of collinearity is addressed ($L_2$ penalty) in conjunction with shrinkage of redundant variables  ($L_1$ penalty). The degree of grouping correlated variables is modulated by the parameter $\alpha$.
%		
			\begin{equation}
			\begin{split}
			\hat{\beta}&=\min\limits_{\beta\in R^{p+1}}[\frac{1}{2N}\sum\limits_{i=1}^{N} (y_i-x_i^t\beta)^2 +\lambda P_\alpha(\beta)]\\
			P_\alpha(\beta)&=\sum\limits_{j=1}^{P}[\frac{1}{2}(1-\alpha) \beta_j^2+\alpha|\beta_j|]
			\end{split}
			\label{eq:EN}
			\end{equation}
%
We augment \eqref{eq:EN} while keeping the overall structure and characteristics of the Elastic Net, i.e. the quadratic structure in the $L_2$ penalty. The reparameterization of the LMM allows the penalty function to be dependant on both the fixed and random effects in the model $\tilde{P}_\alpha(\beta,d)$. %The penalty is increasing in both parameters, while allowing for an interaction between the variables which are candidates for both types of effects.

In addition correlated random effects can be included in the final model selection whereas in the Adaptive LASSO settings this was not possible, thus overcoming the problematic testing of simultaneous random effects \cite{ChenDunson2003}. The LMMEN is defined as the following:
%
\begin{equation}
\label{eq:MLE-EN}
  \begin{split}
    Q(\phi|y,b)&=||y-ZD\Gamma b-X\beta||^2+\tilde{P}_\alpha(\beta,d)\\
    \tilde{P}_\alpha(\beta,d)&=\frac{1}{2}(1-\alpha)[\lambda_2^f\sum\limits_{i\in P}\beta_i^2+\lambda_2^r\sum\limits_{j\in Q}d_j^2]+\alpha[\lambda_1^f\sum\limits_{i \in P}|\beta_i|+\lambda_1^r\sum\limits_{j \in Q}|d_j|]
  \end{split}
\end{equation}
%
When the final model is not a mixed effects model, but either a fixed effects or random effects model then the original form of $P_\alpha$ is applied.
		
% 		\begin{subequations}
% 			\begin{equation}
% 			\label{eq:FEM}	
% 				\tilde{P}_\alpha(\beta,d)|_{||d||=0}=\frac{1}{2}(1-\alpha)(\lambda_2^f\sum\limits_{i\in P}\beta_i^2)+\alpha(\lambda_1^f\sum\limits_{i \in P}|\beta_i|)
% 			\end{equation}
% 			\begin{equation}
% 			\label{eq:REM}
% 				\tilde{P}_\alpha(\beta,d)|_{||\beta||=0}=\frac{1}{2}(1-\alpha)(\lambda_2^r\sum\limits_{j\in Q}d_j^2)+\alpha(\lambda_1^r\sum\limits_{j \in Q}|d_j|)
% 			\end{equation}
% 		\end{subequations}

\section{Asymptotics}
Assume that the data $\{(X_i,Z_i,y_i); \text{ } i=1...m\}$ is a random sample of $m$ subjects from a linear mixed-effects model with a probability density function $f(y_i|X_i,Z_i,\phi)$. Let $y_i$ be an $n_i \times 1$ response measurements for subject $i$, $X_i$ be an $n_i \times p$ design matrix of explanatory variables, and $Z_i$ be an $n_i \times q$ design matrix of random effects.

Let $\phi=(\beta',d',\gamma')'$, where $\beta \in \mathbb{R}^p$, $d \in \mathbb{R}^q$ and $\gamma$ is of the dimension $\frac{q(q-1)}{2}$. $p=m^{\alpha}$ is the number of fixed effects, and $q=m^{\delta}$ the number of the random effects to be estimated. Then number of free elements in the covariance matrix of the random effects, $\Phi$, is $\frac{q(q-1)}{2}$.

In \cite{BKG2010} the hyperparameters satisfy $\alpha < 1$ and $\delta < 1$ giving a setup of $m>p$, $m>q$. The total number of unknown hyper parameters is $k=p+\frac{q(q+1)}{2}\ll m$. In this paper we are letting $\alpha > 1$ , $\delta < 1$ giving a framework of $m<p$ , $m>q$, i.e. a high-dimensional problem. The total number of unknown parameters that are estimated in this framework is $k=m^{\alpha}+\frac{m^{\delta}(m^{\delta}+1)}{2}\gg m$.

Let $L_i(\phi)=\text{log}(f(y_i|X_i,Z_i,\phi))$ denote the contribution of observation $i$ to the log-likelihood function, given by:
\begin{equation}
L_i(\phi)=-\frac{1}{2}\text{log}|\textbf{V}_i|-\frac{1}{2}(\textbf{y}_i-\textbf{X}_i\beta)'(\textbf{V}_i)^{-1}(\textbf{y}_i-\textbf{X}_i\beta),
\label{eq:loglik}
\end{equation}
where $\textbf{V}_i=\sigma^2(Z_iD\Gamma\Gamma'DZ_i+I_{n_i})$. Let $L(\phi)=\sum\limits_{i=1}^{m}L_i(\phi)$ and $Q(\phi)$ denote the log-likelihood and the penalized log-likelihood. 

In the following theorems we prove in the appendix that under regularity conditions
\begin{enumerate}
  \item[$C1$] The Fisher information matrix $I(\phi_{10})$ knowing $\phi_{20}=0$ is finite and positive definite.
  \item[$C2$] There exists a subset $\Theta$ of $\mathbb{R}^k$, containing the true parameter $\phi_0$ such that $L_i(\phi)$ given in the \ref{eq:loglik} admits all third order derivatives, which are continuous and bounded.
\end{enumerate}
\begin{thm}
  \label{thm1}
    Let $\phi=(\phi'_1,0')'$, and the observations follow the LMM model satisfying conditions $C1,C2$. If $m^{-B}\lambda_m\rightarrow 0$, then there exists a local maximizer $\hat{\phi}=\begin{pmatrix}
    \hat{\phi_1} \\ 0 \end{pmatrix}$ of $Q\begin{Bmatrix}\begin{pmatrix}
    \hat{\phi_1} \\ 0 \end{pmatrix}\end{Bmatrix}$ such that $\hat{\phi_1}$ is $m^{-B}$, $B>0$, consistent for $\phi_{10}$.
  \end{thm}

\begin{thm}
\label{thm2}
Let the observations follow the LMM model satisfying conditions $C1,C2$. If $\lambda_m \rightarrow \infty$ then with probability tending to 1 for any given $\phi_1$ satisfying $||\phi_1-\phi_{10}||_1\le Mm^{-1/2}$ and some constant $M>0$,

  $$ Q\left\lbrace\left( 
		\begin{array}{c}
			\phi_1 \\ 0
		\end{array}
		\right)  \right\rbrace
		=\max\limits_{||\phi_2||_1\le Mm^{-1/2}}
	Q\left\lbrace\left( 
		\begin{array}{c}
		\phi_1 \\ \phi_2
		\end{array}
		\right)\right\rbrace.
	$$ 
\end{thm}

\section{Simulations}
Simulation testing the model selection performance were carried out on five scenarios. In each scenario 100 data sets were simulated from a multivariate normal density. $$y_i\sim N(X_i\beta,\sigma^2(Z_i\Psi Z^t_i+I_{n_i}))$$
The true values of $(\beta_1,\beta_2)=(1,1)$, and the true variance covariance matrix
		$$ \Psi= \left( 
		\begin{array}{ccc}
			9   & 4.8 & 0.6 \\
			4.8 & 4   & 1   \\
			0.6 & 1   & 1 
		\end{array}
		\right) $$
The parameterization of the five scenarios are defined in Table \ref{tab:Scenario} as:\\
\begin{table}[ht]
		  \centering
		  \caption{Simulation Scenarios}
\ %vspace{-10pt}
\scalebox{0.8}{
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\multirow{2}{*}{Scenario} &   Subjects & Obs per subject & Fixed Effects & Random Effects & Correlation \\
\cline{2-6}
\multicolumn{ 1}{|c|}{} &          m &      $n_i$ &          p &          q &     $\rho$ \\ \hline
         1 & 30 & 5  & 9 & 4  &  no  \\ 
         2 & 60 & 10 & 9 & 4  &  no  \\ 
         3 & 60 & 5  & 9 & 10 &  no  \\ 
         4 & 60 & 10 & 9 & 4  &  Multicollin \\
         5 & 30 & 5 & 200 & 4  &  p>n \\ 
         \hline
\end{tabular}}
\label{tab:Scenario}
\end{table}

The first three scenarios are taken from the \cite{BKG2010} to test the LMMEN to its counterpart ``Penalized Linear Mixed Effects Model"  (Pen.LME). The true model under consideration in scenarios 1 and 2 is defined as model \eqref{eq:scen1} and scenario 3 where $X=Z$ as model \eqref{eq:scen2}.
\begin{subequations}
\begin{align}
y_{ij}&=b_{i1}+\beta_1x_{ij1}+\beta_2x_{ij2}+b_{i2}Z_{ij1}+b_{i3}Z_{ij2}+\epsilon_{ij} &\qquad \epsilon_{ij}\sim N(0,1) 
\label{eq:scen1}
\\
y_{ij}&=b_{i1}+(\beta_1+b_{i2})x_{ij1}+b_{i3}X_{ij3}+\epsilon_{ij} &\qquad  \epsilon_{ij}\sim N(0,1)
\label{eq:scen2}
\end{align}
\end{subequations}
Scenario 4 tests the model performance under settings that there is a high correlation between fixed variables. The scenario uses the same data as scenario 2 and replaces $X_3$ with a linear combination of {$X_1$,$X_2$} where $X_3=wX_1+(1-w)X_2+\epsilon$ where $\epsilon\sim N(0,\tau)$. This introduces high correlation in the first three fixed effects, in this setting the LASSO and Adaptive Lasso discard one of these fixed effects thus rendering the model selection inferior. The final scenario tests the performance in high dimension settings. The number of fixed effects is increased to 200 and the first 20 are real parameters while the remainder 180 are nuisance, the random effects remain as in the previous scenarios. This scenario can only be run under LMMEN since the initial values are not calculated using the solution of an unpenalized mixed model, as in the Pen.LME.

The first panel of figures \ref{fig:glmmensim} depict the distribution of each parameter estimated within each scenario, where the fixed effects are on the left hand side and the standard deviations of the random effects are on the right hand side. The results of the LMMEN (black) is compared to the Pen.LME (grey). The first three scenarios' results are comparable between the two methods, where the real parameters are chosen consistently. In the fourth scenario the LMMEN selects all the covariates while distributing relatively equal weights to each one. The Pen.LME's adaptive lasso penalty can not discern between the highly correlated variables and sets the 3rd fixed effect near to zero a high percent of the time. In addition, we see that there is no loss of performance in the LMMEN in that it excludes the nuisance fixed effects and correctly estimating the random effects. In the fifth scenario the LMMEN selects the first 20 fixed parameters persistently while setting to zero the nuisance fixed effects, while correctly estimating the random effects. 
%
\begin{figure}[ht]
\centering
<<scenario,echo=F,fig=TRUE,width=14,height=11>>=
p4
@
\caption{Simulation results of the five scenarios defined in Table \ref{tab:Scenario}. Each row is a different scenario, while the left hand side of the panel depict the distribution of the simulated estimated fixed effects parameters, the right hand side depicts the distribution of the estimated random effect parameters. The grey boxplots are the results of the Pen.LME and the black boxplots are the LMMEN.}
\label{fig:glmmensim}
\end{figure}
%
The second panel of results \ref{fig:oracle} show the mean percent of variables correctly selected for the whole model, only the fixed effects and only the random effects for each scenario. This measures performance of model selection without the constraint of an oracle property. For example, in the first scenario of LMMEN 89\% of the percent of the variables were correctly selected. We see that the two methods perform similarly, where in the second scenario the Pen.LME out-performed the LMMEN. In high dimension scenario the LMMEN selected 94\% of the correct variables on average. Comparing the performance of selecting the all the parameters perfectly, oracle quality, we see that both selections methods results are tempered. In scenario one, the LMMEN selects the perfect model 38\% of the time, while comparatively the Pen.LME perfectly selects 50\% of the simulations. We see that in the multicollinearity scenario (4), the LMMEN out-performs the Pen.LME selecting all three correct fixed effects 25\% of the time, while the Pen.LME 4\%. As expected the in the fifth scenario the LMMEN was not able to select all 200 variables correctly in any of the simulations. 
%
\begin{figure}[h]
\centering
<<oracle,echo=F,fig=TRUE,width=14,height=8>>=
p.compare
@
\caption{Model selection performance comparison of Pen.LME (grey) and the LMMEN (black) for the simulations defined in Table \ref{tab:Scenario}. The panel columns from left to right are the selection performance by entire model, the fixed effects and the random effects. The panel rows depict the performance statistic, the upper row is the mean percent of parameters selected correctly, the bottom row measures the oracle property of each model.}
\label{fig:oracle}
\end{figure}
%
\section{Case Study}
The LMMEN algorithm was tested on high dimensional panel data accumulated as part the \href{http://www.goodjudgmentproject.com/}{Good Judgment Project} within the Aggregative Contingent Estimation (ACE) Program \footnote{Sponsored by the U.S. Intelligence Advanced Research Projects Activity (IARPA).}. The aim of this program is \textit{``to dramatically enhance the accuracy, precision, and timeliness of forecasts for a broad range of event types, through the development of advanced techniques that elicit, weight, and combine the judgments of many intelligence analysts."}. The study is characterized as a longitudinal study where probabilistic forecasts are derived from crowd sentiment.

The Good Judgment team recruited approximately 3,000 users in the first year. Those users were randomly assigned to 12 groups. Each user can answer an active question at any time until the question is closed, and 75 questions were active over the first year. This design is a natural one for a repeated measures model with random effects, in which the questions are designated as subjects with random intercepts and for each group a random effect is estimated. In addition there are 40 fixed variables that contain demographic, psychological and past performance information. The data tested was 100 random samples of 50 answers from 20 randomly sampled questions, giving a block structure of 1,000 observations. 
%
The LMMEN with specifications for the design structure will be compared to the Elastic Net algorithm, within the GLMNET R library\footnote{version 2.0-2 was used in the simulations, \href{http://cran.r-project.org/web/packages/glmnet/index.html}{Homepage}} \cite{FHT2010}, which assumes an unstructured covariance design and crossvalidated levels of scaling parameters. The simple mean is used as the baseline aggregation method. Two levels of algorithm performance will be investigated, first is the model selection and second is the accuracy of the aggregated predictions. The statistic which will be used to test performance of the aggregated  predictions is the Brier score. In this case study only binary events are taken under consideration\footnote{6 questions are omitted under this constraint.} thus the Brier score equation is defined as
\begin{equation}
	BS=\frac{1}{N} \sum\limits_{t=1}^{N}(f_{t}-o)^2,
\end{equation}
in which $f$ is the prediction and $o$ is the question outcome at time $t$ and $N$ is the number of prediction instances.
%
\begin{figure}
\centering
<<casepanel,echo=F,fig=TRUE,width=18,height=13>>=
grid.newpage()
pushViewport(viewport(layout=grid.layout(2,2)))
print(p_eps_f+ggtitle("Fixed Effects Persistence (a)"),vp=vplayout(1,1))
print(p_eps_r+ggtitle("Random Effects Persistence (b)"),vp=vplayout(1,2))
print(p_scat+ggtitle("Brier Score Comparison (c)"),vp=vplayout(2,1))
print(p_mae+ggtitle("Mean Absolute Prediction Error (d)"),vp=vplayout(2,2))
@
\caption{Model performance of GLMNET and LMMEN tested on 100 random samples of 1000 observations from the Good Judgment study. Panel (a) compares the distribution of fixed effects selection persistency between the two methods. Panel (b) depicts the random effects selection persistency of the LMMEN. Panel (c) compares the probabilistic forecast accuracy of the two methods using the Brier Score as the loss function. Panel (d) compares the distribution of the mean absolute prediction error of each method}
\label{fig:perform}
\end{figure}
%
First we compare the model selection between the two algorithms as seen in panel (a) of Figure \ref{fig:perform}. It can be seen that the LMMEN produces a higher level of sparsity than the GLMNET and the variables chosen are persistent in the simulation.
The addition of the design structure allows us to select random effects found in the data. The groups of users are assumed to be distributed normally with a variation parameter. After applying the LMMEN the optimal solution produces a sparse covariance matrix with relation to the random effects. The results of this selection can be found in panel (b) of Figure \ref{fig:perform}. We see that the variance estimate of groups \{1B,1C,4A,4B,4C\} is equal to zero in a large percent of the simulations, thus concluding that there is no difference between the user responses in those groups.

The second level of performance investigated is the prediction accuracy. The estimated non-zero covariates after selection are used to aggregate out of sample user predictions of active questions. The results of the two selection methods can be found in panel (c) of Figure \ref{fig:perform}. We see that both methods have low brier scores, i.e. the aggregated predictions are close to the final outcome. The average brier scores for GLMNET and LMMEN are .089 and .085 respectively. This shows that there is no major loss of prediction accuracy between the two selection methods. Both methods out perform the benchmark aggregation (grand mean) which has an average brier score of 0.11. The more significant difference as seen in panel (d) of Figure \ref{fig:perform} is the mean absolute prediction error, where in this case the average estimation error in the GLMNET is larger than the LMMEN. This reinforces the importance of modeling the structure of the data correctly in order to minimize errors in estimation.
\section{Discussion}
In the paper we have shown that fixed and random effects in high dimensional linear mixed models can be simultaneous selected. This selection method introduces the ability to select variables under conditions of multicollinearity both in the fixed and random effects. This method, LMMEN, furthers current variable selection of these models with the introduction of a ridge penalty into the optimization.

It was found through simulations that this method correctly selects fixed and random effects under sparse data designs. Simulations were carried out under the Gaussian assumption for both the conditional distribution and the distribution of the random effects. Further simulations will be carried out which relax the assumption of the conditional distribution. When testing the LMMEN in the case study the variable selection was comparable to a similar regularization method which does not model the covariance structure, GLMNET. The LMMEN gave further insight into the characteristics of groups of users, where a subset of them were found not have prediction difference within the groups.

This paper applies the Brier Score (L2 loss) as the loss function to tune the penalty parameters in the case study. One could calibrate the penalty parameters is the intraclass correlation (ICC) levels. The ICC is  intrinsic to random effects models, and is regularly used for evaluating the level of correlation between different groups as defined by the model. Applying the LMMEN while calibrating to minimize the ICC could be a vital tool for correctly selecting candidate random effects to model the data design and will be assessed in future work.
\pagebreak
\bibliography{lmmen_bib}{}
\newpage
\section{Appendix}
\input{Asymp1.tex}
\end{document}